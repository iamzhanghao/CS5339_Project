{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS5339 Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Pos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x172373950>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from tempfile import mkstemp\n",
    "from shutil import move, copymode\n",
    "from os import fdopen, remove\n",
    "import re\n",
    "\n",
    "def replace(file_path):\n",
    "    #Create temp file\n",
    "    fh, abs_path = mkstemp()\n",
    "    with fdopen(fh,'w') as new_file:\n",
    "        with open(file_path) as old_file:\n",
    "            for line in old_file:\n",
    "                new_file.write(re.sub(\"  \" , \" \", line))\n",
    "\n",
    "    #Copy the file permissions from the old file to the new file\n",
    "    copymode(file_path, abs_path)\n",
    "    #Remove original file\n",
    "    remove(file_path)\n",
    "    #Move new file\n",
    "    move(abs_path, file_path)\n",
    "\n",
    "# replace('aclImdb/test-neg.txt')\n",
    "# replace('aclImdb/train-pos.txt')\n",
    "# replace('aclImdb/test-pos.txt')\n",
    "# replace('aclImdb/test-neg.txt')\n",
    "# replace('aclImdb/train-unsup.txt')\n",
    "replace('aclImdb/alldata.txt')\n",
    "\n",
    "\n",
    "train_neg = pd.read_csv('aclImdb/train-neg.txt', header = None, delimiter = \"\\n\")\n",
    "train_pos = pd.read_csv('aclImdb/train-pos.txt', header = None, delimiter = \"\\n\")\n",
    "train_unsup = pd.read_csv('aclImdb/train-unsup.txt', header = None, delimiter = \"\\n\")\n",
    "test_pos = pd.read_csv('aclImdb/test-pos.txt', header = None, delimiter = \"\\n\")\n",
    "test_neg = pd.read_csv('aclImdb/test-neg.txt', header = None, delimiter = \"\\n\")\n",
    "all_data = pd.read_csv('aclImdb/alldata.txt', header = None, delimiter = \"\\n\")\n",
    "\n",
    "# print(train_neg)\n",
    "data = [train_neg, train_pos, train_unsup, test_pos, test_neg]\n",
    "\n",
    "# print(\"Train Neg\")\n",
    "# train_neg['length'] = cat[0].str.split().map(len)\n",
    "# train_neg.boxplot(column=['length'])\n",
    "# train_neg.plot.hist(bins=12, alpha=0.5)\n",
    "\n",
    "print(\"Train Pos\")\n",
    "all_data['length'] = all_data[0].str.split().map(len)\n",
    "all_data.boxplot(column=['length'])\n",
    "all_data.plot.hist(bins=12, alpha=0.5)\n",
    "\n",
    "\n",
    "# print(train_neg[0][0])\n",
    "\n",
    "# all_data.head(20)\n",
    "\n",
    "\n",
    "\n",
    "# all_train = pd.concat([train_neg, train_pos, train_unsup], ignore_index=True)\n",
    "\n",
    "# all_train.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "https://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48987 docs: 12241 train-sentiment, 12050 test-sentiment, 24696 unlabeled\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from collections import namedtuple\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "SentimentDocument = namedtuple('IMDB', 'words tags split sentiment')\n",
    "\n",
    "alldocs = []  # will hold all docs in original order\n",
    "# with open('aclImdb/alldata-id.txt') as alldata:\n",
    "#     for line_no, line in enumerate(alldata):\n",
    "#         tokens = gensim.utils.to_unicode(line).split()\n",
    "#         words = tokens[1:]\n",
    "#         tags = [line_no] \n",
    "        \n",
    "#         # 25k train, 25k test, 50k unlabled data\n",
    "#         split = ['train','test','train-unsup','train-unsup'][line_no//25000]  \n",
    "#         # [12.5K pos, 12.5K neg]*2 then 50k unlabled data\n",
    "#         sentiment = [1.0, 0.0, 1.0, 0.0, None, None, None, None][line_no//12500] \n",
    "#         alldocs.append(SentimentDocument(words, tags, split, sentiment))\n",
    "\n",
    "current_line = 0\n",
    "with open('aclImdb/train-neg.txt') as alldata:\n",
    "    for line_no, line in enumerate(alldata):\n",
    "        \n",
    "        tokens = gensim.utils.to_unicode(line).split()\n",
    "        if len(tokens)<=200:\n",
    "            continue\n",
    "        words = tokens[1:]\n",
    "        tags = [current_line]\n",
    "        current_line += 1\n",
    "        split = 'train'\n",
    "        sentiment = 0\n",
    "        alldocs.append(SentimentDocument(words, tags, split, sentiment))\n",
    "        \n",
    "with open('aclImdb/train-pos.txt') as alldata:\n",
    "    for line_no, line in enumerate(alldata):\n",
    "        tokens = gensim.utils.to_unicode(line).split()\n",
    "        if len(tokens)<=200:\n",
    "            continue\n",
    "        words = tokens[1:]\n",
    "        tags = [current_line]\n",
    "        current_line += 1\n",
    "        split = 'train'\n",
    "        sentiment = 1.0\n",
    "        alldocs.append(SentimentDocument(words, tags, split, sentiment))\n",
    "        \n",
    "with open('aclImdb/test-pos.txt') as alldata:\n",
    "    for line_no, line in enumerate(alldata):\n",
    "        tokens = gensim.utils.to_unicode(line).split()\n",
    "        if len(tokens)<=200:\n",
    "            continue\n",
    "        words = tokens[1:]\n",
    "        tags = [current_line]\n",
    "        current_line += 1\n",
    "        split = 'test'\n",
    "        sentiment = 1.0\n",
    "        alldocs.append(SentimentDocument(words, tags, split, sentiment))\n",
    "        \n",
    "with open('aclImdb/test-neg.txt') as alldata:\n",
    "    for line_no, line in enumerate(alldata):\n",
    "        tokens = gensim.utils.to_unicode(line).split()\n",
    "        if len(tokens)<=200:\n",
    "            continue\n",
    "        words = tokens[1:]\n",
    "        tags = [current_line]\n",
    "        current_line += 1\n",
    "        split = 'test'\n",
    "        sentiment = 0\n",
    "        alldocs.append(SentimentDocument(words, tags, split, sentiment))\n",
    "        \n",
    "\n",
    "\n",
    "with open('aclImdb/train-unsup.txt') as alldata:\n",
    "    for line_no, line in enumerate(alldata):\n",
    "        tokens = gensim.utils.to_unicode(line).split()\n",
    "        if len(tokens)<=200:\n",
    "            continue\n",
    "        words = tokens[1:]\n",
    "        tags = [current_line]\n",
    "        current_line += 1\n",
    "        split = 'train-unsup'\n",
    "        sentiment = None\n",
    "        alldocs.append(SentimentDocument(words, tags, split, sentiment))\n",
    "\n",
    "train_docs = [doc for doc in alldocs if doc.split == 'train']\n",
    "test_docs = [doc for doc in alldocs if doc.split == 'test']\n",
    "unlabeled = [doc for doc in alldocs if doc.split == 'train-unsup']\n",
    "doc_list = alldocs[:]  # for reshuffling per epoch\n",
    "\n",
    "print('%d docs: %d train-sentiment, %d test-sentiment, %d unlabeled' % (len(doc_list), len(train_docs), len(test_docs), len(unlabeled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB(words=['only', 'recently', 'found', 'out', 'that', 'madeleine', \"l'engle's\", 'novel', 'had', 'been', 'turned', 'into', 'a', 'tv', 'movie', 'by', 'disney', 'and', 'ordered', 'the', 'dvd', '.', 'the', 'book', 'was', 'a', 'favorite', 'of', 'mine', 'when', 'i', 'was', 'a', 'child', 'and', 'i', 'read', 'it', 'several', 'times', '.', 'despite', 'some', 'of', 'the', 'child', 'actors', 'not', 'resembling', 'the', 'characters', 'as', 'described', 'in', 'the', 'novel', ',', 'the', 'murry', 'family', 'is', 'well', 'cast', ',', 'with', 'a', 'likable', '(', 'if', 'too', 'pretty', ')', 'meg', 'at', 'the', 'center', 'and', 'a', 'charles', 'wallace', 'who', 'is', 'convincing', 'as', 'a', 'child', 'prodigy', 'without', 'becoming', 'irritating', '.', 'the', 'first', 'half', 'hour', 'is', 'promising', 'enough', ',', 'doing', 'a', 'good', 'job', 'in', 'establishing', 'the', 'relationships', 'between', 'the', 'lead', 'characters', 'and', 'at', 'setting', 'the', 'scene', '.', 'unfortunately', 'as', 'soon', 'as', 'the', 'non-human', 'characters', 'appear', 'the', 'adaptation', 'starts', 'to', 'unravel', 'and', 'once', 'the', 'children', 'leave', 'earth', 'the', 'whole', 'thing', 'falls', 'apart', '.', 'alfre', 'woodward', 'is', 'too', 'youthful', 'looking', 'and', 'much', 'too', 'regal', 'as', 'the', 'eccentric', 'mrs', 'whatsit', '(', 'think', 'miriam', 'margolis', 'or', 'joan', 'plowright', 'instead', ')', 'and', 'kate', 'nelligan', 'face', 'is', 'so', 'mask', 'like', 'and', 'inexpressive', ',', 'she', 'must', 'have', 'visited', 'faye', \"dunaway's\", 'plastic', 'surgeon', 'in', 'recent', 'years', '.', 'for', 'some', 'reason', 'they', 'make', 'her', 'mrs', 'which', 'look', 'like', 'glinda', 'from', 'the', 'wizard', 'of', 'oz', 'when', 'she', 'should', 'have', 'resembled', 'a', 'benign', 'wicked', 'witch', 'of', 'the', 'west', '.', 'in', 'the', 'end', 'what', 'lets', 'this', 'down', 'most', 'badly', 'are', 'the', 'terrible', 'special', 'effects', 'and', 'art', 'direction', '.', 'i', 'understand', 'that', 'this', 'is', 'a', 'tv', 'movie', ',', 'but', 'the', 'cgi', 'looked', 'like', 'something', 'that', 'could', 'have', 'been', 'done', '15', 'years', 'earlier', '.', 'mrs', \"whatsits'\", 'centaur', 'incarnation', 'is', 'a', 'disaster', 'as', 'is', 'the', 'chewbacca', 'like', 'suit', 'for', 'aunt', 'beast', ',', 'who', 'in', 'the', 'novel', 'is', 'a', 'velvety', ',', 'elegant', 'creature', 'instead', 'of', 'the', 'ungainly', 'big', 'foot', 'like', 'thing', 'shown', 'here', '.', 'i', 'could', 'go', 'on', 'and', 'on', ',', 'nearly', 'every', 'artistic', 'choice', 'is', 'a', 'disaster', ',', 'presumably', 'because', 'there', \"wasn't\", 'a', 'large', 'enough', 'budget', 'to', 'do', 'this', 'justice', ',', 'but', 'also', 'because', 'the', 'design', 'work', 'lacks', 'imagination', 'and', 'good', 'judgement', '.', 'this', 'really', 'would', 'have', 'needed', 'the', 'sense', 'of', 'wonder', 'spielberg', 'brought', 'to', 'his', 'early', 'films', '.', 'what', 'a', 'shame', 'that', 'with', 'the', 'current', 'popularity', 'of', 'adapting', \"children's\", 'literary', 'fantasy', 'series', 'nobody', 'thought', 'of', 'adapting', 'a', 'wrinkle', 'in', 'time', 'and', \"it's\", 'sequels', 'for', 'the', 'big', 'screen', ',', 'giving', 'it', 'the', 'scope', 'it', 'deserves', '.'], tags=[199], split='train', sentiment=0) \n",
      "\n",
      "IMDB(words=['a', 'very', 'good', 'comedy', 'movie', '.', 'ijust', 'liked', 'it', '.', 'i', \"don't\", 'know', 'why', 'i', 'love', 'this', 'movie', 'i', 'just', 'love', 'it', '.', 'storyline', ':', 'it', 'is', 'a', 'story', 'of', 'two', 'boys', 'amar', '(', 'aamir', 'khan', ')', 'and', 'prem', '(', 'salman', 'khan', ')', 'who', 'want', 'to', 'get', 'rich', 'quickly', 'by', 'taking', 'all', 'the', 'short-cuts', 'in', 'the', 'book', '.', 'amar', 'is', 'the', 'son', 'of', 'an', 'honest', 'barber', ',', 'murli', 'manohar', '(', 'deven', 'verma', ')', 'in', 'mumbai', ',', 'while', 'prem', 'is', 'the', 'son', 'of', 'bankeylal', 'bhopali', '(', 'jagdeep', ')', ',', 'a', 'hardworking', 'tailor', 'in', 'bhopal', '.', 'both', 'amar', 'and', 'prem', 'sell', 'their', \"father's\", 'shop', 'and', 'house', 'respectively', ',', 'and', 'zero', 'in', 'on', 'a', 'hill', 'station', 'where', 'a', 'beautiful', 'wealthy', 'heiress', 'raveena', '(', 'raveena', 'tandon', ')', 'has', 'come', 'from', 'london', 'accompanied', 'by', 'her', 'friend', 'cum', 'secretary', 'karishma', '(', 'karishma', 'kapoor', ')', 'with', 'the', 'intention', 'of', 'getting', 'married', 'to', 'a', 'virtuous', 'indian', '.', 'the', 'lucky', 'man', 'to', 'wed', 'raveena', 'will', 'inherit', 'her', 'father', 'ram', 'gopal', \"bajaj's\", '(', 'paresh', 'rawal', ')', 'entire', 'wealth', '.', 'amar', 'and', 'prem', 'see', 'their', 'get', 'rich', 'quick', 'chance', 'and', 'woo', 'raveena', ',', 'each', 'trying', 'to', 'out', 'do', 'the', 'other', '.', 'enter', 'teja', '(', 'paresh', 'rawal', 'in', 'a', 'double', 'role', ')', 'whose', 'sole', 'ambition', 'in', 'life', 'has', 'been', 'to', 'grab', 'his', 'twin', 'brother', 'ram', 'gopal', \"bajaj's\", 'millions', '.', 'so', 'teja', 'plants', 'bhalla', '.', '(', 'shehzad', ')', 'and', 'robert', '(', 'vijoo', 'khote', ')', 'in', \"raveena's\", 'house', ',', 'to', 'help', 'him', 'in', 'fulfill', 'his', 'ambition', '.', 'as', 'the', 'story', 'progresses', 'it', 'turns', 'out', 'to', 'be', 'a', 'mad', 'chase', 'from', 'ram', 'gopal', \"bajaj's\", 'wealth', ',', 'full', 'of', 'humor', ',', 'romance', 'thrills', 'and', 'chills', '.', 'will', 'raveena', '&', 'karishma', 'see', 'through', 'amar', 'and', \"prem's\", 'mischievous', 'intentions', '?', 'will', 'teja', 'succeed', 'in', 'his', 'motives', '?', 'see', 'it', 'all', 'in', 'super', 'comedy', 'andaz', 'apna', 'apna', '.', 'aamir', ',', 'salman', ',', 'raveena', ',', 'karishma', 'and', 'paresh', 'at', 'there', 'best', '.', 'good', 'music', '.', 'good', 'direction', '.', 'good', 'story', 'and', 'screenplay', '.', 'and', 'very', 'good', 'comedy', '!', '!', '!', '!', '!', '!'], tags=[17000], split='test', sentiment=1.0) \n",
      "\n",
      "IMDB(words=['spoilers*', 'in', 'this', 'would-be', 'satire', ',', 'chaplin', 'set', 'his', 'sights', 'on', 'the', 'evils', 'of', 'german', 'fascism', ',', 'playing', 'the', 'twin', 'roles', 'of', 'tomanian', 'dictator', 'adenoid', 'hynkel', 'and', 'one', 'of', 'his', 'subjects', ',', 'an', 'inadvertent', 'world', 'war', 'i', 'hero', 'and', 'jewish', 'barber', '.', 'through', 'events', 'inspired', 'by', 'both', 'adolf', 'hitler', 'and', 'the', 'marx', 'brothers', ',', 'hynkel', 'negotiates', 'contracts', 'and', 'declares', 'war', 'on', 'neighbouring', 'osterlich', 'whilst', 'finding', 'time', 'for', 'numerous', ',', 'oddly', 'flat', 'set-pieces', '.', 'the', \"dictator's\", 'much-celebrated', 'waltz', 'with', 'an', 'inflatable', 'globe', 'is', 'actually', 'entirely', 'heavyhanded', ',', 'underwhelming', 'and', 'unfunny', '.', 'chaplin', 'should', 'certainly', 'be', 'commended', 'for', 'looking', 'to', 'lampoon', 'hitler', 'and', 'for', 'speaking', 'out', 'strongly', 'on', 'celluloid', '-', 'his', 'much-maligned', 'final', 'speech', 'is', 'actually', 'the', 'bold', ',', 'memorable', 'highlight', 'of', 'the', 'piece', '-', 'but', 'the', 'film', 'simply', \"isn't\", 'sharp', 'or', 'funny', 'enough', 'to', 'merit', 'the', 'praise', 'frequently', 'heaped', 'upon', 'it', ',', 'nor', 'to', 'demand', 'repeated', 'viewings', '.', 'the', 'best', 'gags', 'are', 'away', 'from', \"hynkel's\", 'tiresome', 'posturing', 'and', 'involve', 'the', 'barber', 'attempting', 'to', 'avoid', 'a', 'large', 'spinning', 'bomb', '(', 'a', 'sequence', 'which', 'steals', 'from', 'the', 'gun', 'tussle', 'in', 'the', 'gold', 'rush', ')', 'and', 'later', ',', 'with', 'a', 'pot', 'on', 'his', 'head', ',', 'accidentally', 'walking', 'the', 'plank', 'off', 'the', 'roof', 'of', 'his', 'shop', '.', 'compared', 'to', 'the', \"director's\", 'silent', 'classics', ',', 'the', 'great', 'dictator', 'is', 'slow', ',', 'wildly', 'inconsistent', 'and', 'altogether', 'somewhat', 'unsatisfactory', ',', 'whilst', 'the', 'barren', 'spells', 'between', 'laughs', 'are', 'often', 'long', 'and', 'difficult', 'to', 'endure', '.', 'there', 'is', 'no', 'doubt', 'that', 'chaplin', 'was', 'a', 'genius', ',', 'but', 'even', 'geniuses', 'make', 'disappointing', 'pictures', 'and', 'the', 'great', 'dictator', 'certainly', 'ranks', 'as', 'such', '.'], tags=[20000], split='test', sentiment=0)\n"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "print(doc_list[199],'\\n')\n",
    "print(doc_list[17000],'\\n')\n",
    "print(doc_list[20000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Cores 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/gensim/models/doc2vec.py:574: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PV-DM/C Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12)\n",
      "PV-DBOW Doc2Vec(dbow,d100,n5,mc2,s0.001,t12)\n",
      "PV-DM/M Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "print('CPU Cores',cores)\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"this will be painfully slow otherwise\"\n",
    "\n",
    "models = [\n",
    "    # PV-DM w/concatenation  window size = 5  approximates paper's 10-word total window size\n",
    "    Doc2Vec(dm=1, dm_concat=1, size=100, window=5, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    # PV-DBOW \n",
    "    Doc2Vec(dm=0, size=100, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    # PV-DM w/average\n",
    "    Doc2Vec(dm=1, dm_mean=1, size=100, window=10, negative=5, hs=0, min_count=2, workers=cores),\n",
    "]\n",
    "\n",
    "# speed setup by sharing results of 1st model's vocabulary scan\n",
    "models[0].build_vocab(alldocs)  # PV-DM/concat requires one special NULL word so it serves as template\n",
    "print('PV-DM/C', models[0])\n",
    "models[1].reset_from(models[0])\n",
    "print('PV-DBOW', models[1])\n",
    "models[2].reset_from(models[0])\n",
    "print('PV-DM/M', models[2])\n",
    "\n",
    "models_by_name = OrderedDict((str(model), model) for model in models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "best_error = defaultdict(lambda :1.0)  # to selectively-print only best errors achieved\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from random import sample\n",
    "\n",
    "# for timing\n",
    "from contextlib import contextmanager\n",
    "from timeit import default_timer\n",
    "import time \n",
    "\n",
    "@contextmanager\n",
    "def elapsed_timer():\n",
    "    start = default_timer()\n",
    "    elapser = lambda: default_timer() - start\n",
    "    yield lambda: elapser()\n",
    "    end = default_timer()\n",
    "    elapser = lambda: end-start\n",
    "    \n",
    "def logistic_predictor_from_data(train_targets, train_regressors):\n",
    "    logit = sm.Logit(train_targets, train_regressors)\n",
    "    predictor = logit.fit(disp=0)\n",
    "    #print(predictor.summary())\n",
    "    return predictor\n",
    "\n",
    "def error_rate_for_model(test_model, train_set, test_set, infer=False, infer_steps=3, infer_alpha=0.1, infer_subsample=0.1):\n",
    "    \"\"\"Report error rate on test_doc sentiments, using supplied model and train_docs\"\"\"\n",
    "\n",
    "    train_targets, train_regressors = zip(*[(doc.sentiment, test_model.docvecs[doc.tags[0]]) for doc in train_set])\n",
    "    train_regressors = sm.add_constant(train_regressors)\n",
    "    predictor = logistic_predictor_from_data(train_targets, train_regressors)\n",
    "\n",
    "    test_data = test_set\n",
    "    if infer:\n",
    "        if infer_subsample < 1.0:\n",
    "            test_data = sample(test_data, int(infer_subsample * len(test_data)))\n",
    "        test_regressors = [test_model.infer_vector(doc.words, steps=infer_steps, alpha=infer_alpha) for doc in test_data]\n",
    "    else:\n",
    "        test_regressors = [test_model.docvecs[doc.tags[0]] for doc in test_docs]\n",
    "    test_regressors = sm.add_constant(test_regressors)\n",
    "    \n",
    "    # predict & evaluate\n",
    "    test_predictions = predictor.predict(test_regressors)\n",
    "    corrects = sum(np.rint(test_predictions) == [doc.sentiment for doc in test_data])\n",
    "    errors = len(test_predictions) - corrects\n",
    "    error_rate = float(errors) / len(test_predictions)\n",
    "    return (error_rate, errors, len(test_predictions), predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training word vectors and doc vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START 2020-04-18 19:20:17.263464\n",
      "*0.499004 : 1 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 0.0s 0.2s\n",
      "*0.482988 : 1 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12)_inferred 0.0s 4.1s\n",
      "*0.499004 : 1 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 0.0s 0.2s\n",
      "*0.490456 : 1 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12)_inferred 0.0s 1.4s\n",
      "*0.499004 : 1 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 0.0s 0.2s\n",
      "*0.497925 : 1 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12)_inferred 0.0s 1.9s\n",
      "completed pass 1 at alpha 0.025000\n",
      "*0.375851 : 2 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 18.0s 0.2s\n",
      "*0.262407 : 2 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 9.7s 0.3s\n",
      "*0.269544 : 2 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 12.6s 0.2s\n",
      "completed pass 2 at alpha 0.023800\n",
      "*0.286141 : 3 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 36.8s 0.2s\n",
      "*0.139917 : 3 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 18.9s 0.3s\n",
      "*0.196017 : 3 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 26.2s 0.4s\n",
      "completed pass 3 at alpha 0.022600\n",
      "*0.223568 : 4 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 57.2s 0.2s\n",
      "*0.117012 : 4 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 24.6s 0.2s\n",
      "*0.170622 : 4 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 39.0s 0.2s\n",
      "completed pass 4 at alpha 0.021400\n",
      "*0.186390 : 5 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 78.1s 0.3s\n",
      "*0.187552 : 5 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12)_inferred 78.1s 4.4s\n",
      "*0.112448 : 5 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 36.4s 0.3s\n",
      "*0.109544 : 5 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12)_inferred 36.4s 2.0s\n",
      "*0.157593 : 5 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 56.7s 0.2s\n",
      "*0.164315 : 5 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12)_inferred 56.7s 2.1s\n",
      "completed pass 5 at alpha 0.020200\n",
      "*0.173278 : 6 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 91.2s 0.2s\n",
      "*0.112116 : 6 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 44.2s 0.3s\n",
      "*0.150871 : 6 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 66.4s 0.5s\n",
      "completed pass 6 at alpha 0.019000\n",
      "*0.164315 : 7 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 108.7s 0.3s\n",
      "*0.109710 : 7 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 56.5s 0.2s\n",
      "*0.145145 : 7 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 78.8s 0.2s\n",
      "completed pass 7 at alpha 0.017800\n",
      "*0.163900 : 8 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 119.0s 0.2s\n",
      " 0.112033 : 8 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 58.6s 0.2s\n",
      "*0.145145 : 8 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 83.7s 0.2s\n",
      "completed pass 8 at alpha 0.016600\n",
      "*0.159170 : 9 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 130.4s 0.2s\n",
      "*0.109129 : 9 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 61.7s 0.2s\n",
      "*0.141494 : 9 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 92.6s 0.2s\n",
      "completed pass 9 at alpha 0.015400\n",
      " 0.160000 : 10 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 142.4s 0.2s\n",
      "*0.174274 : 10 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12)_inferred 142.4s 3.5s\n",
      " 0.110788 : 10 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 70.8s 0.4s\n",
      " 0.110373 : 10 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12)_inferred 70.8s 1.4s\n",
      "*0.139087 : 10 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 105.8s 0.2s\n",
      " 0.171784 : 10 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12)_inferred 105.8s 1.9s\n",
      "completed pass 10 at alpha 0.014200\n",
      " 0.159253 : 11 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 156.3s 0.2s\n",
      " 0.110788 : 11 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 78.8s 0.2s\n",
      "*0.137261 : 11 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 118.1s 0.2s\n",
      "completed pass 11 at alpha 0.013000\n",
      " 0.161079 : 12 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 176.7s 0.2s\n",
      " 0.111286 : 12 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 90.7s 0.2s\n",
      "*0.136929 : 12 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 139.1s 0.2s\n",
      "completed pass 12 at alpha 0.011800\n",
      "*0.157095 : 13 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 201.6s 0.3s\n",
      " 0.109959 : 13 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 104.6s 0.3s\n",
      "*0.136515 : 13 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 148.9s 0.2s\n",
      "completed pass 13 at alpha 0.010600\n",
      " 0.158091 : 14 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 216.9s 0.4s\n",
      " 0.110290 : 14 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 106.6s 0.2s\n",
      "*0.134855 : 14 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 162.8s 0.2s\n",
      "completed pass 14 at alpha 0.009400\n",
      " 0.158672 : 15 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 232.2s 0.2s\n",
      " 0.181743 : 15 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12)_inferred 232.2s 3.8s\n",
      " 0.110041 : 15 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 131.4s 0.2s\n",
      " 0.119502 : 15 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12)_inferred 131.4s 1.7s\n",
      "*0.133195 : 15 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 193.6s 0.2s\n",
      " 0.177593 : 15 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12)_inferred 193.6s 1.9s\n",
      "completed pass 15 at alpha 0.008200\n",
      "*0.156680 : 16 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 251.8s 0.2s\n",
      " 0.111037 : 16 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 121.8s 0.2s\n",
      "*0.132697 : 16 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 183.7s 0.2s\n",
      "completed pass 16 at alpha 0.007000\n",
      " 0.156763 : 17 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 258.5s 0.2s\n",
      " 0.110788 : 17 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 149.2s 0.4s\n",
      " 0.132863 : 17 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 192.4s 0.2s\n",
      "completed pass 17 at alpha 0.005800\n",
      " 0.158340 : 18 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 260.9s 0.2s\n",
      " 0.109461 : 18 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 135.7s 0.2s\n",
      "*0.132033 : 18 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 210.2s 0.2s\n",
      "completed pass 18 at alpha 0.004600\n",
      "*0.155602 : 19 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 279.0s 0.2s\n",
      " 0.110456 : 19 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 140.6s 0.2s\n",
      " 0.132780 : 19 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 209.8s 0.2s\n",
      "completed pass 19 at alpha 0.003400\n",
      " 0.156929 : 20 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 284.8s 0.2s\n",
      "*0.168465 : 20 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12)_inferred 284.8s 3.5s\n",
      " 0.109212 : 20 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 149.5s 0.2s\n",
      " 0.126141 : 20 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12)_inferred 149.5s 1.3s\n",
      " 0.132282 : 20 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 224.2s 0.2s\n",
      " 0.214108 : 20 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12)_inferred 224.2s 2.2s\n",
      "completed pass 20 at alpha 0.002200\n",
      "END 2020-04-18 21:18:25.251630\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import datetime\n",
    "\n",
    "alpha, min_alpha, passes = (0.025, 0.001, 20)\n",
    "alpha_delta = (alpha - min_alpha) / passes\n",
    "\n",
    "print(\"START %s\" % datetime.datetime.now())\n",
    "\n",
    "for epoch in range(passes):\n",
    "    shuffle(doc_list)  # shuffling gets best results\n",
    "    \n",
    "    for name, train_model in models_by_name.items():\n",
    "        # train\n",
    "        duration = 'na'\n",
    "        train_model.alpha, train_model.min_alpha = alpha, alpha\n",
    "        with elapsed_timer() as elapsed:\n",
    "            train_model.train(doc_list,total_examples=100000, epochs=epoch)\n",
    "            duration = '%.1f' % elapsed()\n",
    "            \n",
    "        # evaluate\n",
    "        eval_duration = ''\n",
    "        with elapsed_timer() as eval_elapsed:\n",
    "            err, err_count, test_count, predictor = error_rate_for_model(train_model, train_docs, test_docs)\n",
    "        eval_duration = '%.1f' % eval_elapsed()\n",
    "        best_indicator = ' '\n",
    "        if err <= best_error[name]:\n",
    "            best_error[name] = err\n",
    "            best_indicator = '*' \n",
    "        print(\"%s%f : %i passes : %s %ss %ss\" % (best_indicator, err, epoch + 1, name, duration, eval_duration))\n",
    "\n",
    "        if ((epoch + 1) % 5) == 0 or epoch == 0:\n",
    "            eval_duration = ''\n",
    "            with elapsed_timer() as eval_elapsed:\n",
    "                infer_err, err_count, test_count, predictor = error_rate_for_model(train_model, train_docs, test_docs, infer=True)\n",
    "            eval_duration = '%.1f' % eval_elapsed()\n",
    "            best_indicator = ' '\n",
    "            if infer_err < best_error[name + '_inferred']:\n",
    "                best_error[name + '_inferred'] = infer_err\n",
    "                best_indicator = '*'\n",
    "            print(\"%s%f : %i passes : %s %ss %ss\" % (best_indicator, infer_err, epoch + 1, name + '_inferred', duration, eval_duration))\n",
    "\n",
    "    print('completed pass %i at alpha %f' % (epoch + 1, alpha))\n",
    "    alpha -= alpha_delta\n",
    "    \n",
    "print(\"END %s\" % str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.109129 Doc2Vec(dbow,d100,n5,mc2,s0.001,t12)\n",
      "0.109544 Doc2Vec(dbow,d100,n5,mc2,s0.001,t12)_inferred\n",
      "0.132033 Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12)\n",
      "0.155602 Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12)\n",
      "0.164315 Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12)_inferred\n",
      "0.168465 Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12)_inferred\n"
     ]
    }
   ],
   "source": [
    "# print best error rates achieved\n",
    "for rate, name in sorted((rate, name) for name, rate in best_error.items()):\n",
    "    print(\"%f %s\" % (rate, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2091286307053942\n",
      "<statsmodels.discrete.discrete_model.BinaryResultsWrapper object at 0x123e37ed0>\n"
     ]
    }
   ],
   "source": [
    "infer_err, err_count, test_count, predictor = error_rate_for_model(train_model, train_docs, test_docs, infer=True)\n",
    "print(infer_err)\n",
    "print(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
