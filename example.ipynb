{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gensim doc2vec & IMDB sentiment dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: section on introduction & motivation\n",
    "\n",
    "TODO: prerequisites + dependencies (statsmodels, patsy, ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch and prep exactly as in Mikolov's go.sh shell script. (Note this cell tests for existence of required files, so steps won't repeat once the final summary file (`aclImdb/alldata-id.txt`) is available alongside this notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# # adapted from Mikolov's example go.sh script: \n",
    "# if [ ! -f \"aclImdb/alldata-id.txt\" ]\n",
    "# then\n",
    "#     if [ ! -d \"aclImdb\" ] \n",
    "#     then\n",
    "#         if [ ! -f \"aclImdb_v1.tar.gz\" ]\n",
    "#         then\n",
    "#           wget --quiet http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "#         fi\n",
    "#       tar xf aclImdb_v1.tar.gz\n",
    "#     fi\n",
    "    \n",
    "#   #this function will convert text to lowercase and will disconnect punctuation and special symbols from words\n",
    "#   function normalize_text {\n",
    "#     awk '{print tolower($0);}' < $1 | sed -e 's/\\./ \\. /g' -e 's/<br \\/>/ /g' -e 's/\"/ \" /g' \\\n",
    "#     -e 's/,/ , /g' -e 's/(/ ( /g' -e 's/)/ ) /g' -e 's/\\!/ \\! /g' -e 's/\\?/ \\? /g' \\\n",
    "#     -e 's/\\;/ \\; /g' -e 's/\\:/ \\: /g' > $1-norm\n",
    "#   }\n",
    "\n",
    "#   export LC_ALL=C\n",
    "#   for j in train/pos train/neg test/pos test/neg train/unsup; do\n",
    "#     rm temp\n",
    "#     for i in `ls aclImdb/$j`; do cat aclImdb/$j/$i >> temp; awk 'BEGIN{print;}' >> temp; done\n",
    "#     normalize_text temp\n",
    "#     mv temp-norm aclImdb/$j/norm.txt\n",
    "#   done\n",
    "#   mv aclImdb/train/pos/norm.txt aclImdb/train-pos.txt\n",
    "#   mv aclImdb/train/neg/norm.txt aclImdb/train-neg.txt\n",
    "#   mv aclImdb/test/pos/norm.txt aclImdb/test-pos.txt\n",
    "#   mv aclImdb/test/neg/norm.txt aclImdb/test-neg.txt\n",
    "#   mv aclImdb/train/unsup/norm.txt aclImdb/train-unsup.txt\n",
    "\n",
    "#   cat aclImdb/train-pos.txt aclImdb/train-neg.txt aclImdb/test-pos.txt aclImdb/test-neg.txt aclImdb/train-unsup.txt > aclImdb/alldata.txt\n",
    "#   awk 'BEGIN{a=0;}{print \"_*\" a \" \" $0; a++;}' < aclImdb/alldata.txt > aclImdb/alldata-id.txt\n",
    "# fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "assert os.path.isfile(\"aclImdb/alldata-id.txt\"), \"alldata-id.txt unavailable\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is small enough to be read into memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 docs: 25000 train-sentiment, 25000 test-sentiment\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple\n",
    "\n",
    "SentimentDocument = namedtuple('SentimentDocument', 'words tags split sentiment')\n",
    "\n",
    "alldocs = []  # will hold all docs in original order\n",
    "with open('aclImdb/alldata-id.txt') as alldata:\n",
    "    for line_no, line in enumerate(alldata):\n",
    "        tokens = gensim.utils.to_unicode(line).split()\n",
    "        words = tokens[1:]\n",
    "        tags = [line_no] # `tags = [tokens[0]]` would also work at extra memory cost\n",
    "        split = ['train','test','extra','extra'][line_no//25000]  # 25k train, 25k test, 25k extra\n",
    "        sentiment = [1.0, 0.0, 1.0, 0.0, None, None, None, None][line_no//12500] # [12.5K pos, 12.5K neg]*2 then unknown\n",
    "        alldocs.append(SentimentDocument(words, tags, split, sentiment))\n",
    "\n",
    "train_docs = [doc for doc in alldocs if doc.split == 'train']\n",
    "test_docs = [doc for doc in alldocs if doc.split == 'test']\n",
    "doc_list = alldocs[:]  # for reshuffling per pass\n",
    "\n",
    "print('%d docs: %d train-sentiment, %d test-sentiment' % (len(doc_list), len(train_docs), len(test_docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up Doc2Vec Training & Evaluation Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximating experiment of Le & Mikolov [\"Distributed Representations of Sentences and Documents\"](http://cs.stanford.edu/~quocle/paragraph_vector.pdf), also with guidance from Mikolov's [example go.sh](https://groups.google.com/d/msg/word2vec-toolkit/Q49FIrNOQRo/J6KG8mUj45sJ):\n",
    "\n",
    "`./word2vec -train ../alldata-id.txt -output vectors.txt -cbow 0 -size 100 -window 10 -negative 5 -hs 0 -sample 1e-4 -threads 40 -binary 0 -iter 20 -min-count 1 -sentence-vectors 1`\n",
    "\n",
    "Parameter choices below vary:\n",
    "\n",
    "* 100-dimensional vectors, as the 400d vectors of the paper don't seem to offer much benefit on this task\n",
    "* similarly, frequent word subsampling seems to decrease sentiment-prediction accuracy, so it's left out\n",
    "* `cbow=0` means skip-gram which is equivalent to the paper's 'PV-DBOW' mode, matched in gensim with `dm=0`\n",
    "* added to that DBOW model are two DM models, one which averages context vectors (`dm_mean`) and one which concatenates them (`dm_concat`, resulting in a much larger, slower, more data-hungry model)\n",
    "* a `min_count=2` saves quite a bit of model memory, discarding only words that appear in a single doc (and are thus no more expressive than the unique-to-each doc vectors themselves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/gensim/models/doc2vec.py:574: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12)\n",
      "Doc2Vec(dbow,d100,n5,mc2,s0.001,t12)\n",
      "Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "print(cores)\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"this will be painfully slow otherwise\"\n",
    "\n",
    "simple_models = [\n",
    "    # PV-DM w/concatenation - window=5 (both sides) approximates paper's 10-word total window size\n",
    "    Doc2Vec(dm=1, dm_concat=1, size=100, window=5, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    # PV-DBOW \n",
    "    Doc2Vec(dm=0, size=100, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    # PV-DM w/average\n",
    "    Doc2Vec(dm=1, dm_mean=1, size=100, window=10, negative=5, hs=0, min_count=2, workers=cores),\n",
    "]\n",
    "\n",
    "# speed setup by sharing results of 1st model's vocabulary scan\n",
    "simple_models[0].build_vocab(alldocs)  # PV-DM/concat requires one special NULL word so it serves as template\n",
    "print(simple_models[0])\n",
    "for model in simple_models[1:]:\n",
    "    model.reset_from(simple_models[0])\n",
    "    print(model)\n",
    "\n",
    "models_by_name = OrderedDict((str(model), model) for model in simple_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the paper, we also evaluate models in pairs. These wrappers return the concatenation of the vectors from each model. (Only the singular models are trained.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "models_by_name['dbow+dmm'] = ConcatenatedDoc2Vec([simple_models[1], simple_models[2]])\n",
    "models_by_name['dbow+dmc'] = ConcatenatedDoc2Vec([simple_models[1], simple_models[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Evaluation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper methods for evaluating error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from random import sample\n",
    "\n",
    "# for timing\n",
    "from contextlib import contextmanager\n",
    "from timeit import default_timer\n",
    "import time \n",
    "\n",
    "@contextmanager\n",
    "def elapsed_timer():\n",
    "    start = default_timer()\n",
    "    elapser = lambda: default_timer() - start\n",
    "    yield lambda: elapser()\n",
    "    end = default_timer()\n",
    "    elapser = lambda: end-start\n",
    "    \n",
    "def logistic_predictor_from_data(train_targets, train_regressors):\n",
    "    logit = sm.Logit(train_targets, train_regressors)\n",
    "    predictor = logit.fit(disp=0)\n",
    "    #print(predictor.summary())\n",
    "    return predictor\n",
    "\n",
    "def error_rate_for_model(test_model, train_set, test_set, infer=False, infer_steps=3, infer_alpha=0.1, infer_subsample=0.1):\n",
    "    \"\"\"Report error rate on test_doc sentiments, using supplied model and train_docs\"\"\"\n",
    "\n",
    "    train_targets, train_regressors = zip(*[(doc.sentiment, test_model.docvecs[doc.tags[0]]) for doc in train_set])\n",
    "    train_regressors = sm.add_constant(train_regressors)\n",
    "    predictor = logistic_predictor_from_data(train_targets, train_regressors)\n",
    "\n",
    "    test_data = test_set\n",
    "    if infer:\n",
    "        if infer_subsample < 1.0:\n",
    "            test_data = sample(test_data, int(infer_subsample * len(test_data)))\n",
    "        test_regressors = [test_model.infer_vector(doc.words, steps=infer_steps, alpha=infer_alpha) for doc in test_data]\n",
    "    else:\n",
    "        test_regressors = [test_model.docvecs[doc.tags[0]] for doc in test_docs]\n",
    "    test_regressors = sm.add_constant(test_regressors)\n",
    "    \n",
    "    # predict & evaluate\n",
    "    test_predictions = predictor.predict(test_regressors)\n",
    "    corrects = sum(np.rint(test_predictions) == [doc.sentiment for doc in test_data])\n",
    "    errors = len(test_predictions) - corrects\n",
    "    error_rate = float(errors) / len(test_predictions)\n",
    "    return (error_rate, errors, len(test_predictions), predictor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using explicit multiple-pass, alpha-reduction approach as sketched in [gensim doc2vec blog post](http://radimrehurek.com/2014/12/doc2vec-tutorial/) – with added shuffling of corpus on each pass.\n",
    "\n",
    "Note that vector training is occurring on *all* documents of the dataset, which includes all TRAIN/TEST/DEV docs.\n",
    "\n",
    "Evaluation of each model's sentiment-predictive power is repeated after each pass, as an error rate (lower is better), to see the rates-of-relative-improvement. The base numbers reuse the TRAIN and TEST vectors stored in the models for the logistic regression, while the _inferred_ results use newly-inferred TEST vectors. \n",
    "\n",
    "(On a 4-core 2.6Ghz Intel Core i7, these 20 passes training and evaluating 3 main models takes about an hour.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "best_error = defaultdict(lambda :1.0)  # to selectively-print only best errors achieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START 2020-04-12 00:15:50.340293\n",
      "*0.499800 : 1 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 0.0s 0.4s\n",
      "*0.488400 : 1 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12)_inferred 0.0s 6.0s\n",
      "*0.499800 : 1 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 0.0s 0.4s\n",
      "*0.488000 : 1 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12)_inferred 0.0s 1.9s\n",
      "*0.499800 : 1 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 0.0s 0.4s\n",
      "*0.512000 : 1 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12)_inferred 0.0s 2.7s\n",
      "completed pass 1 at alpha 0.025000\n",
      "*0.414120 : 2 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 26.3s 0.8s\n",
      "*0.251240 : 2 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 12.2s 0.4s\n",
      "*0.264480 : 2 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 18.3s 0.4s\n",
      "completed pass 2 at alpha 0.023800\n",
      "*0.314880 : 3 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 49.3s 0.4s\n",
      "*0.129600 : 3 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 23.3s 0.4s\n",
      "*0.192120 : 3 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 36.3s 0.4s\n",
      "completed pass 3 at alpha 0.022600\n",
      "*0.236960 : 4 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 73.1s 0.4s\n",
      "*0.112280 : 4 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 35.1s 0.7s\n",
      "*0.169400 : 4 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 54.2s 0.4s\n",
      "completed pass 4 at alpha 0.021400\n",
      "*0.194640 : 5 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 95.1s 0.4s\n",
      "*0.189600 : 5 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12)_inferred 95.1s 5.6s\n",
      "*0.105880 : 5 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 49.9s 0.4s\n",
      "*0.111200 : 5 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12)_inferred 49.9s 2.1s\n",
      "*0.156880 : 5 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 77.2s 0.7s\n",
      "*0.186800 : 5 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12)_inferred 77.2s 2.8s\n",
      "completed pass 5 at alpha 0.020200\n",
      "*0.173680 : 6 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 125.6s 0.4s\n",
      "*0.103160 : 6 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 58.5s 0.4s\n",
      "*0.149040 : 6 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 88.1s 0.4s\n",
      "completed pass 6 at alpha 0.019000\n",
      "*0.165360 : 7 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 134.0s 0.4s\n",
      " 0.104000 : 7 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 68.4s 0.4s\n",
      "*0.145880 : 7 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 106.5s 0.7s\n",
      "completed pass 7 at alpha 0.017800\n",
      "*0.160520 : 8 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 154.6s 0.4s\n",
      " 0.104360 : 8 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 80.6s 0.4s\n",
      "*0.140720 : 8 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 127.7s 0.4s\n",
      "completed pass 8 at alpha 0.016600\n",
      "*0.158640 : 9 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 176.6s 0.4s\n",
      " 0.106640 : 9 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 91.3s 0.4s\n",
      "*0.136840 : 9 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 145.4s 0.5s\n",
      "completed pass 9 at alpha 0.015400\n",
      "*0.155760 : 10 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 202.9s 0.7s\n",
      "*0.173600 : 10 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12)_inferred 202.9s 5.1s\n",
      " 0.106440 : 10 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 103.9s 0.4s\n",
      " 0.115600 : 10 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12)_inferred 103.9s 2.0s\n",
      "*0.134640 : 10 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 164.8s 0.4s\n",
      "*0.180800 : 10 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12)_inferred 164.8s 2.8s\n",
      "completed pass 10 at alpha 0.014200\n",
      "*0.154960 : 11 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 213.6s 0.5s\n",
      " 0.107200 : 11 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 117.1s 0.7s\n",
      "*0.133360 : 11 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 178.7s 0.4s\n",
      "completed pass 11 at alpha 0.013000\n",
      " 0.155040 : 12 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 234.0s 0.4s\n",
      " 0.104920 : 12 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 124.9s 0.4s\n",
      "*0.131440 : 12 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 194.0s 0.4s\n",
      "completed pass 12 at alpha 0.011800\n",
      "*0.153440 : 13 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 250.5s 0.4s\n",
      " 0.107080 : 13 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 135.9s 0.4s\n",
      "*0.130320 : 13 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 212.0s 0.7s\n",
      "completed pass 13 at alpha 0.010600\n",
      " 0.154320 : 14 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 276.0s 0.4s\n",
      " 0.107120 : 14 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 147.7s 0.4s\n",
      " 0.131120 : 14 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 227.6s 0.4s\n",
      "completed pass 14 at alpha 0.009400\n",
      " 0.154080 : 15 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 288.6s 0.4s\n",
      "*0.171600 : 15 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12)_inferred 288.6s 4.8s\n",
      " 0.106720 : 15 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 158.9s 0.4s\n",
      "*0.107600 : 15 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12)_inferred 158.9s 2.2s\n",
      "*0.129720 : 15 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 246.4s 0.4s\n",
      " 0.196800 : 15 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12)_inferred 246.4s 2.7s\n",
      "completed pass 15 at alpha 0.008200\n",
      "*0.153000 : 16 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 305.9s 0.4s\n",
      " 0.106960 : 16 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 170.0s 0.4s\n",
      "*0.129600 : 16 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 263.3s 0.4s\n",
      "completed pass 16 at alpha 0.007000\n",
      " 0.153600 : 17 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 329.0s 0.4s\n",
      " 0.106440 : 17 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 182.4s 0.7s\n",
      " 0.129880 : 17 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 281.7s 0.4s\n",
      "completed pass 17 at alpha 0.005800\n",
      " 0.153480 : 18 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 345.4s 0.4s\n",
      " 0.106040 : 18 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 195.7s 0.4s\n",
      "*0.129240 : 18 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 303.9s 0.4s\n",
      "completed pass 18 at alpha 0.004600\n",
      " 0.154160 : 19 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 365.2s 0.4s\n",
      " 0.106640 : 19 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 204.2s 1.1s\n",
      "*0.129160 : 19 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 317.7s 0.4s\n",
      "completed pass 19 at alpha 0.003400\n",
      " 0.154360 : 20 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12) 385.1s 0.4s\n",
      " 0.183600 : 20 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12)_inferred 385.1s 5.0s\n",
      " 0.106160 : 20 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12) 215.8s 0.4s\n",
      " 0.114400 : 20 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t12)_inferred 215.8s 2.0s\n",
      "*0.128840 : 20 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12) 334.1s 0.7s\n",
      " 0.231600 : 20 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12)_inferred 334.1s 2.7s\n",
      "completed pass 20 at alpha 0.002200\n",
      "END 2020-04-12 02:56:57.940329\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import datetime\n",
    "\n",
    "alpha, min_alpha, passes = (0.025, 0.001, 20)\n",
    "alpha_delta = (alpha - min_alpha) / passes\n",
    "\n",
    "print(\"START %s\" % datetime.datetime.now())\n",
    "\n",
    "for epoch in range(passes):\n",
    "    shuffle(doc_list)  # shuffling gets best results\n",
    "    \n",
    "    for name, train_model in models_by_name.items():\n",
    "        # train\n",
    "        duration = 'na'\n",
    "        train_model.alpha, train_model.min_alpha = alpha, alpha\n",
    "        with elapsed_timer() as elapsed:\n",
    "            train_model.train(doc_list,total_examples=100000, epochs=epoch)\n",
    "            duration = '%.1f' % elapsed()\n",
    "            \n",
    "        # evaluate\n",
    "        eval_duration = ''\n",
    "        with elapsed_timer() as eval_elapsed:\n",
    "            err, err_count, test_count, predictor = error_rate_for_model(train_model, train_docs, test_docs)\n",
    "        eval_duration = '%.1f' % eval_elapsed()\n",
    "        best_indicator = ' '\n",
    "        if err <= best_error[name]:\n",
    "            best_error[name] = err\n",
    "            best_indicator = '*' \n",
    "        print(\"%s%f : %i passes : %s %ss %ss\" % (best_indicator, err, epoch + 1, name, duration, eval_duration))\n",
    "\n",
    "        if ((epoch + 1) % 5) == 0 or epoch == 0:\n",
    "            eval_duration = ''\n",
    "            with elapsed_timer() as eval_elapsed:\n",
    "                infer_err, err_count, test_count, predictor = error_rate_for_model(train_model, train_docs, test_docs, infer=True)\n",
    "            eval_duration = '%.1f' % eval_elapsed()\n",
    "            best_indicator = ' '\n",
    "            if infer_err < best_error[name + '_inferred']:\n",
    "                best_error[name + '_inferred'] = infer_err\n",
    "                best_indicator = '*'\n",
    "            print(\"%s%f : %i passes : %s %ss %ss\" % (best_indicator, infer_err, epoch + 1, name + '_inferred', duration, eval_duration))\n",
    "\n",
    "    print('completed pass %i at alpha %f' % (epoch + 1, alpha))\n",
    "    alpha -= alpha_delta\n",
    "    \n",
    "print(\"END %s\" % str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Achieved Sentiment-Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.103160 Doc2Vec(dbow,d100,n5,mc2,s0.001,t12)\n",
      "0.107600 Doc2Vec(dbow,d100,n5,mc2,s0.001,t12)_inferred\n",
      "0.128840 Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12)\n",
      "0.153000 Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12)\n",
      "0.171600 Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12)_inferred\n",
      "0.180800 Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12)_inferred\n"
     ]
    }
   ],
   "source": [
    "# print best error rates achieved\n",
    "for rate, name in sorted((rate, name) for name, rate in best_error.items()):\n",
    "    print(\"%f %s\" % (rate, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my testing, unlike the paper's report, DBOW performs best. Concatenating vectors from different models only offers a small predictive improvement. The best results I've seen are still just under 10% error rate, still a ways from the paper's 7.42%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are inferred vectors close to the precalculated ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for doc 59103...\n",
      "Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12):\n",
      " [(59103, 0.7466343641281128), (84048, 0.5244645476341248), (35561, 0.4812113046646118)]\n",
      "Doc2Vec(dbow,d100,n5,mc2,s0.001,t12):\n",
      " [(59103, 0.9532005190849304), (62285, 0.5763416290283203), (36914, 0.5581868886947632)]\n",
      "Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12):\n",
      " [(59103, 0.7127737998962402), (51851, 0.6521816253662109), (48467, 0.6454958915710449)]\n"
     ]
    }
   ],
   "source": [
    "doc_id = np.random.randint(simple_models[0].docvecs.count)  # pick random doc; re-run cell for more examples\n",
    "print('for doc %d...' % doc_id)\n",
    "for model in simple_models:\n",
    "    inferred_docvec = model.infer_vector(alldocs[doc_id].words)\n",
    "    print('%s:\\n %s' % (model, model.docvecs.most_similar([inferred_docvec], topn=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Yes, here the stored vector from 20 epochs of training is usually one of the closest to a freshly-inferred vector for the same words. Note the defaults for inference are very abbreviated – just 3 steps starting at a high alpha – and likely need tuning for other applications.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do close documents seem more related than distant ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET (38986): «when i went to see this movie it was already a forced choice , as my original intent was sold out . what ensuited then was sheer terror , this movie is so bad i could hardly bear it . the story is not worth mention , a gay goalkeeper forms a gay soccer team to play against his old straight team who - on discovering his sexual orientation - gave him a hard time . loaded with unbearably old and overused clichés of gays , the thin plot matches perfectly the inane dialogues . . . it is absolutely astonishing that actors as dietmar bär or charly hübner waste their talent and time on such nonsense . 1/10»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dbow,d100,n5,mc2,s0.001,t12):\n",
      "\n",
      "MOST (16769, 0.49240642786026): «american pie : beta house is sort of in limbo between genres . on the one hand , it's a comedy with no plot and few genuinely clever jokes . on the other hand , it's porno that's a tad too soft-core to actually turn on any viewers . essentially beta house is a collage of sex scenes - some humiliating , others just lame attempts at humor - with a couple thin plot points thrown in an effort at cohesiveness . the characters are barely even two-dimensional , most development relies on knowledge of naked mile , and the \" important \" plot scenes are so far apart that you wonder why the writers even felt the need for a story . in all fairness , i did not go into this movie without expectations . i liked the original three american pie movies , and thought band camp and naked mile were solid rentals . i thought naked mile was almost good enough to be released in theaters , and so when i saw that some of the same characters were returning for beta house , i was excited to see this installment . i was aware that there would be numerous scenes of debauchery and sexual humiliation in multiple forms . and i was fine with it , because in the past , these scenes were backed by the story and were well integrated into the plot . in beta house , however , it's almost as if the writers forgot why the formula in the other ap movies worked . they spent too much energy working in the nudity that they forgot to actually write a story . this movie is a disappointment and not even worth a one-dollar rental . the jokes are lame , the story is non-existent , and the porno-aspect is too tame if that's all you really care about seeing .»\n",
      "\n",
      "MEDIAN (93770, 0.16113492846488953): «i actually found this dvd in supermarket basket full of discount products . 3 , 50 is not much , especially when it's says : the most funniest comedy since \" there's something about mary \" starring : ben stiller , janeane garofalo , mike meyers , alanna ubach and many others . . . alanna ubach is the hot number from \" meet the fockers \" and janeane garofalo ( which i personally like as well ) known for her work with ben stiller on \" reality bites \" , \" mystery men \" and lot's of other projects . so i rushed to the counter to make this disc ( full of visual moments of adventure ) all mine . i honestly did expected much more from the storyline , i couldn't watch it in one time , it's getting so boring so i took couple of days of interval before i finished the movie . sorry , but in such cases i rather read something in between . but at the same time if they had more money on this project . they probably did much better job than the final result . sound and visual shout for improvement . crap movies like \" the whole 9 yards \" for example , had much , much more financial backup so they get more attention and credit . i would say , nice try , they did it because they have guts , less afraid to fail . bruce willis started with \" the moonlightning \" as well . look at him , he managed to survive that and he's big boy now . but retail price 3 , 50 is exact wright amount to ask for , no one deserve to get reach on this movie . this is kind of a student-introduction movie and not like : hey , give me your wallet !»\n",
      "\n",
      "LEAST (89734, -0.18241722881793976): «as a portlander , i always get suspicious if a movie gets filmed in oregon : \" the postman \" was probably the worst example , but there have been others . by this logic , \" untraceable \" should suck . it turns out that the movie's main problem isn't acting or continuity goofs or anything like that ( although i should affirm that i believe that there are a few too many movies about people looking for killers ) . it appears to be the possibility that the movie glorifies spying . could it be that someone is trying to give the government some good pr in the wake of the nsa scandal ? the right wing always says that it wants to get \" big government \" out of people's lives , but always turns around and spies on everyone . anyway , i don't recommend this movie . starring diane lane and colin hanks . ps : what i mean by \" arthur voiced elmer \" is that there's a character named arthur james elmer . we looney tunes fans know that elmer fudd's voice was provided by arthur q . bryan . yes , i know that it's totally unrelated , but just something that i notice .»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "doc_id = np.random.randint(simple_models[0].docvecs.count)  # pick random doc, re-run cell for more examples\n",
    "model = random.choice(simple_models)  # and a random model\n",
    "sims = model.docvecs.most_similar(doc_id, topn=model.docvecs.count)  # get *all* similar documents\n",
    "print(u'TARGET (%d): «%s»\\n' % (doc_id, ' '.join(alldocs[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(alldocs[sims[index][0]].words)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Somewhat, in terms of reviewer tone, movie genre, etc... the MOST cosine-similar docs usually seem more like the TARGET than the MEDIAN or LEAST.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the word vectors show useful similarities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "word_models = simple_models[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most similar words for 'ott' (78 occurences)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t12)</th><th>Doc2Vec(dbow,d100,n5,mc2,s0.001,t12)</th><th>Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t12)</th></tr><tr><td>[('over-the-top', 0.6089898943901062),<br>\n",
       "('histrionic', 0.5998550653457642),<br>\n",
       "('absurd', 0.5788363218307495),<br>\n",
       "('hammy', 0.5662363767623901),<br>\n",
       "('banal', 0.5611444711685181),<br>\n",
       "('overdone', 0.553699791431427),<br>\n",
       "('cheesy', 0.551530122756958),<br>\n",
       "('exaggerated', 0.5491220951080322),<br>\n",
       "('nonsensical', 0.5457489490509033),<br>\n",
       "('outrageous', 0.544755220413208),<br>\n",
       "('amateurish', 0.5411003828048706),<br>\n",
       "('melodramatic', 0.5316254496574402),<br>\n",
       "('corny', 0.5312181711196899),<br>\n",
       "('ridiculous', 0.531184196472168),<br>\n",
       "('unconvincing', 0.5283622741699219),<br>\n",
       "('contrived', 0.5263482928276062),<br>\n",
       "('laughable', 0.5254546403884888),<br>\n",
       "('overwrought', 0.5192746520042419),<br>\n",
       "('trite', 0.5185801982879639),<br>\n",
       "('stiff', 0.5175385475158691)]</td><td>[('repercussion', 0.4127863645553589),<br>\n",
       "('preform', 0.4025324583053589),<br>\n",
       "(\"hilter's\", 0.38194864988327026),<br>\n",
       "(\"bix's\", 0.3777480125427246),<br>\n",
       "('fortier', 0.37674254179000854),<br>\n",
       "('conflate', 0.3704046607017517),<br>\n",
       "('family-less', 0.3702741265296936),<br>\n",
       "('blood-frosting', 0.36308619379997253),<br>\n",
       "('sit-com', 0.36305761337280273),<br>\n",
       "('frumpish', 0.3627118766307831),<br>\n",
       "('severs', 0.3617934584617615),<br>\n",
       "('crapiness', 0.3558298945426941),<br>\n",
       "('cooker', 0.35284870862960815),<br>\n",
       "('theorize', 0.3489653468132019),<br>\n",
       "(\"net'\", 0.3482373356819153),<br>\n",
       "('brenna', 0.34773606061935425),<br>\n",
       "('recreating', 0.3475387394428253),<br>\n",
       "('stupefied', 0.3467150330543518),<br>\n",
       "('senegal', 0.34607475996017456),<br>\n",
       "('vanna', 0.3453220725059509)]</td><td>[('over-the-top', 0.4830499589443207),<br>\n",
       "('naturalistic', 0.4666609764099121),<br>\n",
       "('ominous', 0.4453126788139343),<br>\n",
       "('scornful', 0.4357379078865051),<br>\n",
       "('permissible', 0.4337683916091919),<br>\n",
       "('comical', 0.4285312294960022),<br>\n",
       "('orange', 0.4279036521911621),<br>\n",
       "('cheeky', 0.4272797107696533),<br>\n",
       "('socking', 0.4185159206390381),<br>\n",
       "('stylised', 0.4166119694709778),<br>\n",
       "('unsettling', 0.41254761815071106),<br>\n",
       "('childish', 0.4097590148448944),<br>\n",
       "('elfen', 0.4059644341468811),<br>\n",
       "('comedically', 0.4056779742240906),<br>\n",
       "('damaging', 0.4040599465370178),<br>\n",
       "(\"scrat's\", 0.4039596617221832),<br>\n",
       "('ultra-cool', 0.4021921157836914),<br>\n",
       "('creaking', 0.40052059292793274),<br>\n",
       "('overacted', 0.39773380756378174),<br>\n",
       "('outlandish', 0.3973613381385803)]</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from IPython.display import HTML\n",
    "# pick a random word with a suitable number of occurences\n",
    "while True:\n",
    "    word = random.choice(word_models[0].wv.index2word)\n",
    "    if word_models[0].wv.vocab[word].count > 10:\n",
    "        break\n",
    "# or uncomment below line, to just pick a word from the relevant domain:\n",
    "#word = 'comedy/drama'\n",
    "similars_per_model = [str(model.most_similar(word, topn=20)).replace('), ','),<br>\\n') for model in word_models]\n",
    "similar_table = (\"<table><tr><th>\" +\n",
    "    \"</th><th>\".join([str(model) for model in word_models]) + \n",
    "    \"</th></tr><tr><td>\" +\n",
    "    \"</td><td>\".join(similars_per_model) +\n",
    "    \"</td></tr></table>\")\n",
    "print(\"most similar words for '%s' (%d occurences)\" % (word, simple_models[0].wv.vocab[word].count))\n",
    "HTML(similar_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the DBOW words look meaningless? That's because the gensim DBOW model doesn't train word vectors – they remain at their random initialized values – unless you ask with the `dbow_words=1` initialization parameter. Concurrent word-training slows DBOW mode significantly, and offers little improvement (and sometimes a little worsening) of the error rate on this IMDB sentiment-prediction task. \n",
    "\n",
    "Words from DM models tend to show meaningfully similar words when there are many examples in the training data (as with 'plot' or 'actor'). (All DM modes inherently involve word vector training concurrent with doc vector training.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the word vectors from this dataset any good at analogies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `accuracy` (Method will be removed in 4.0.0, use self.evaluate_word_analogies() instead).\n",
      "  \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'questions-words.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-42e16b0baaaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# note: this takes many minutes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_models\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'questions-words.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'correct'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'incorrect'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s: %0.2f%% correct (%d of %d)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mincorrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mincorrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                 )\n\u001b[0;32m-> 1447\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(self, questions, restrict_vocab, most_similar, case_insensitive)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0msections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 \u001b[0;31m# TODO: use level3 BLAS (=evaluate multiple questions at once), for speed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     )\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, ignore_ext, buffering, encoding, errors)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'questions-words.txt'"
     ]
    }
   ],
   "source": [
    "# assuming something like\n",
    "# https://word2vec.googlecode.com/svn/trunk/questions-words.txt \n",
    "# is in local directory\n",
    "# note: this takes many minutes\n",
    "for model in word_models:\n",
    "    sections = model.wv.accuracy('questions-words.txt')\n",
    "    correct, incorrect = len(sections[-1]['correct']), len(sections[-1]['incorrect'])\n",
    "    print('%s: %0.2f%% correct (%d of %d)' % (model, float(correct*100)/(correct+incorrect), correct, correct+incorrect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though this is a tiny, domain-specific dataset, it shows some meager capability on the general word analogies – at least for the DM/concat and DM/mean models which actually train word vectors. (The untrained random-initialized words of the DBOW model of course fail miserably.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "This cell left intentionally erroneous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To mix the Google dataset (if locally available) into the word tests..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "w2v_g100b = Word2Vec.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "w2v_g100b.compact_name = 'w2v_g100b'\n",
    "word_models.append(w2v_g100b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get copious logging output from above steps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "rootLogger = logging.getLogger()\n",
    "rootLogger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To auto-reload python code while developing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
